<p>
</p>

<h3>说明</h3>
<p>Dir 类似于文件系统中的 inode. 其指向于磁盘上的一断连续的存储, 被称着 fragments.
而 <b>fragments</b>的结构中, 有一个头 Doc. 所有的 Dir 使用 Cache ID 生成的 hash 值来跟踪.</p>

<p><b>Dir</b>是作为内存的常驻内容的, 这意味着<b>Dir</b>的大小是受到限制的不能太多, 现在是设计是 10 字节.
这意味着, 可以存在 <b>Dir</b>的内存收到了一些限制. 同时也意味着, 对于 MISS 的状态, 是没有必要
进行 IO 操作的, 这是一个很大的性能提升.</p>

<p>另一点在于, 一个 stripe 只要初始化了, directory 的大小就定了, 不会修改.
其大小与 stripe 的大小大致是线性的. 就是这个原因, 所以 ats 的内存占用与磁盘大小有关系.
也因为, directory 的大小确定了, 不会再改变, 所以更多的内存保存到缓存, 并不会占用更多的内存.
如果当缓存是空的时候, 内存可以让 ats 运行, 那么当缓存满的时候也可以运行.
<img src=http://cdn.fengidri.me/blog/cache-directory-structure.png >
每一个<b>Dir</b>保存有一个 offset 还有一个 size. <b>Dir</b>中的 size 是一个近似的大小, 当然相对于
<b>fragments</b>的实际大小来说, 只大不小. 精确的数据 size 保存于 <b>fragments</b>的头里.</p>

<p>注意: 检查 HTTP 头的信息的时候, 必须要有磁盘 I/O, 包括 object 的 URL.</p>

<p>整个 directory 是一个 hash 表, 使用链表的方式来解决冲突. 因为每一个 <b>Dir</b>很小, 所以直接做为
hash bucket 的链表的头.</p>

<p>Chaining 的实现是通过对于 directory 中的 <b>Dir</b>的结构进行组织实现的. 第一级的是 direcotry bucket.
这是固定数量的 <b>Dir</b>(目前是 4 个, 使用宏 <b>DIR_DEPTH</b>定义). 这作为一个基础的 hash bucket,
并且第一个 <b>Dir</b>是这个 hash bucket 的 root.</p>

<p>所有的Directory buckets被组织进了 segments. stripe 中的所有的 segments有相同数量的 buckets. stripe 中包含的
segments的数量是指定的, 所以 segments中包含有尽可能多, 但是不越过 16384 的 bucket.</p>

<p><img src=http://cdn.fengidri.me/blog/1461910024.8631.4020 >
每一个<b>Dir</b>都有一个 next index 还有一个 previous index 用于链接同一个segments中的其它的<b>Dir</b>.
因为一个segments下面的<b>Dir</b>数量不会超过(2^16 -1 ), 所以 16 位的空间就可以用于保存 index value.
在 stripe 的头里, 包含有由若干 <b>Dir</b>索引组成的 array, 这些做为 free list 的 roots,
每一个 segments有一个. 可用的 <b>Dir</b>使用 bucket 结构进行保存. 当 stripe 进行初始化的时候,
每一个 bucket 的 第一个 <b>Dir</b>被初始为 0, 其它的 <b>Dir</b>被放到对应的 segments下的 free list 中.
这意味着, 每一个 Directory buckets的第一个 <b>Dir</b>作为 hash bucket 的 root, 所以被标记为 unused, 而不是
放到 free list. bucket 中的其它 <b>Dir</b>会被优先用于添加到相应的散列桶中, 但是这并不是必须的.
segments的 free list 在初始化的时候, 其它的 <b>Dir</b>被有序地, 增加进来, 先是所有的 seconds, 然后是
所有的 thirds, 再然后是 所有的第四个. 当要在一个 bucket 中增加一个新的 <b>Dir</b>, 会在free list
中从第一个, 查到最后一个, 这个时, 最大数的限制性就会发挥作用.</p>

<p><img src=http://cdn.fengidri.me/blog/1461910077.19824.2498 >
<b>Dir</b>会被从 free list 中删除, 当使用的时候. 如果不再使用了就会返回.
当一个 fragment 有必要放到 directory 的时候, 使用 Cache ID 来定位 hash bucket.
如果, bucket 中的第一个 <b>Dir</b>还是未被使用的, 就使用它. 如果没有, 那么 bucket 中的其它的 <b>Dir</b>会被查找, 如果在 free list, 就会直接使用. 如果, 在没有找到, 就会使用 free list 中的第一个.
这个 <b>Dir</b>会被增加到这个 bucket 中.</p>

<h3>dir_insert</h3>
<p><pre>
int
dir_insert(const CacheKey *key, Vol *d, Dir *to_part)
{
  int s = key-&gt;slice32(0) % d-&gt;segments; // 得到当前的 segments index
  int bi = key-&gt;slice32(1) % d-&gt;buckets; // 得到 segments 的 buckets index
  int l;

  Dir *seg = dir_segment(s, d); // 得到 segments 实例
  Dir *b = dir_bucket(bi, seg); // 得到 buckets 的实例
  Dir *e = NULL;
  Vol *vol = d;

Lagain:
  // get from this row first
  e = b;
  if (dir_is_empty(e))
    goto Lfill; // 找到一个空的
  for (l = 1; l &lt; DIR_DEPTH; l++) { // 在 bucket 里找
    e = dir_bucket_row(b, l);
    if (dir_is_empty(e)) { // 找到了
      unlink_from_freelist(e, s, d); // 从 freelist 中删除
      goto Llink;
    }
  }
  // get one from the freelist
  e = freelist_pop(s, d); // bucket 里的四个都已经被使用了, 直接使用 freelist 中的第一个
  if (!e)
    goto Lagain; // 没有找到就再找一次, 这样做的目的是什么? 不怕死循环吗? TODO
Llink: // 放到 bucket 来
  dir_set_next(e, dir_next(b));
  dir_set_next(b, dir_to_offset(e, seg));
Lfill:
  dir_assign_data(e, to_part); // 复制数据
  dir_set_tag(e, key-&gt;slice32(2));
  ink_assert(vol_offset(d, e) &lt; (d-&gt;skip + d-&gt;len));
  DDebug("dir_insert", "insert %p %X into vol %d bucket %d at %p tag %X %X boffset %" PRId64 "", e, key-&gt;slice32(0), d-&gt;fd, bi, e,
         key-&gt;slice32(1), dir_tag(e), dir_offset(e));
  CHECK_DIR(d);
  d-&gt;header-&gt;dirty = 1;
  CACHE_INC_DIR_USED(d-&gt;mutex);
  return 1;
}
</pre>
</p>

<p>问题是, 当整个磁盘都已经使用完了, 之后就应该是over write 了. 这里是如何实现的?</p>
